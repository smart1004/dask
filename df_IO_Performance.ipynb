{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@bobhaffner/gist-to-medium-test-db3d51b8ba7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'yellow_tripdata_2017-01.csv'\n",
    "csv_file_on = 'yellow_tripdata_2017-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.5 s\n",
      "9,710,124 rows\n"
     ]
    }
   ],
   "source": [
    "# https://data.world/nyc-taxi-limo/yellow-tripdata-january-2017\n",
    "\n",
    "%time pd_frame = pd.read_csv('yellow_tripdata_2017-01.csv')\n",
    "print ('{:,} rows'.format(len(pd_frame)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-09 11:13:28</td>\n",
       "      <td>2017-01-09 11:25:45</td>\n",
       "      <td>1</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-09 11:32:27</td>\n",
       "      <td>2017-01-09 11:36:01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-09 11:38:20</td>\n",
       "      <td>2017-01-09 11:42:05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>164</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-09 11:52:13</td>\n",
       "      <td>2017-01-09 11:57:36</td>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>249</td>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>52.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2017-01-09 11:13:28   2017-01-09 11:25:45                1   \n",
       "1         1  2017-01-09 11:32:27   2017-01-09 11:36:01                1   \n",
       "2         1  2017-01-09 11:38:20   2017-01-09 11:42:05                1   \n",
       "3         1  2017-01-09 11:52:13   2017-01-09 11:57:36                1   \n",
       "4         2  2017-01-01 00:00:00   2017-01-01 00:00:00                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.30           1                  N           263           161   \n",
       "1           0.90           1                  N           186           234   \n",
       "2           1.10           1                  N           164           161   \n",
       "3           1.10           1                  N           236            75   \n",
       "4           0.02           2                  N           249           234   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         12.5    0.0      0.5        2.00           0.0   \n",
       "1             1          5.0    0.0      0.5        1.45           0.0   \n",
       "2             1          5.5    0.0      0.5        1.00           0.0   \n",
       "3             1          6.0    0.0      0.5        1.70           0.0   \n",
       "4             2         52.0    0.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3         15.30  \n",
       "1                    0.3          7.25  \n",
       "2                    0.3          7.30  \n",
       "3                    0.3          8.50  \n",
       "4                    0.3         52.80  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%time dd_to_pd_frame = dd.read_csv(csv_file).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "#%time fastparquet.write(csv_file_on+'.parq', pd_frame, compression='SNAPPY')\n",
    "%time fastparquet.write(csv_file_on+'.parq', pd_frame, compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D 드라이브의 볼륨: d_data\n",
      " 볼륨 일련 번호: 98F6-9C55\n",
      "\n",
      " D:\\home\\a_dask 디렉터리\n",
      "\n",
      "2019-02-05  오전 10:17    <DIR>          .\n",
      "2019-02-05  오전 10:17    <DIR>          ..\n",
      "2019-02-05  오전 09:54    <DIR>          .ipynb_checkpoints\n",
      "2019-02-05  오전 05:23            23,743 a01_dask_delayed.ipynb\n",
      "2019-02-05  오전 09:49    <DIR>          a_dask-dataframe-benchmarking\n",
      "2019-01-27  오전 07:28             8,874 Dashboard.ipynb\n",
      "2019-01-27  오전 07:29    <DIR>          dask-worker-space\n",
      "2019-02-05  오전 04:31            15,292 dask.dataframe_01.ipynb\n",
      "2019-02-05  오전 04:50             9,646 dask.dataframe_03.ipynb\n",
      "2019-02-02  오전 10:43             3,061 dask_ml.preprocessing_01.ipynb\n",
      "2019-02-05  오전 03:41             3,652 Distributed_random_forests.ipynb\n",
      "2019-02-05  오전 05:08            73,494 map_partitions_01.ipynb\n",
      "2019-01-29  오후 10:30             6,007 memory_usage.ipynb\n",
      "2019-02-05  오전 05:21            15,939 mydask.png\n",
      "2019-02-05  오전 10:12    <DIR>          nyc-taxi-limo-yellow-tripdata-january-2017\n",
      "2019-02-05  오전 10:11       153,313,461 nyc-taxi-limo-yellow-tripdata-january-2017.zip\n",
      "2019-01-29  오후 09:42             6,512 rolling.ipynb\n",
      "2019-02-02  오전 10:20             1,421 test.py\n",
      "2019-02-05  오전 10:17             2,199 Untitled.ipynb\n",
      "2019-02-05  오전 01:10       854,903,002 yellow_tripdata_2017-01.csv\n",
      "2019-02-05  오전 10:17       129,956,783 yellow_tripdata_2017-01.parq\n",
      "              15개 파일       1,138,343,086 바이트\n",
      "               6개 디렉터리  381,353,844,736 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# dask parquet\n",
    "dd_to_pd_frame.to_parquet(csv_file_on+'_dask.parq', compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%time parq_to_pd = fastparquet.ParquetFile(csv_file_on+'.parq').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42 s\n"
     ]
    }
   ],
   "source": [
    "%time dd_parq_to_dd_frame = dd.read_parquet(csv_file_on+'.parq').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%time dd_parq_to_dd_frame = dd.read_parquet(csv_file_on+'.parq', engine='fastparquet').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dd_parq_to_dd_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%time pd_frame.to_hdf(csv_file_on+'.h5','tripdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.73 s\n"
     ]
    }
   ],
   "source": [
    "%time hdf_to_pd_frame = pd.read_hdf(csv_file_on+'.h5','tripdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del hdf_to_pd_frame\n",
    "# del dd_parq_to_dd_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-eb1ba60da3dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#dd.read_hdf('myfile.1.hdf5', '/x')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# dd_to_pd_frame = dd.read_hdf(pattern='yellow_tripdata_2017.1.h5', key='/x') #.compute()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdd_to_pd_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yellow_tripdata_2017.1.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'/df'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#.compute()\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\programdata\\psc_env\\lib\\site-packages\\dask\\dataframe\\io\\hdf.py\u001b[0m in \u001b[0;36mread_hdf\u001b[1;34m(pattern, key, start, stop, columns, chunksize, sorted_index, lock, mode)\u001b[0m\n\u001b[0;32m    422\u001b[0m                                     \u001b[0msorted_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                                     lock=lock, mode=mode)\n\u001b[1;32m--> 424\u001b[1;33m                    for path in paths])\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\psc_env\\lib\\site-packages\\dask\\dataframe\\io\\hdf.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    422\u001b[0m                                     \u001b[0msorted_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                                     lock=lock, mode=mode)\n\u001b[1;32m--> 424\u001b[1;33m                    for path in paths])\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\psc_env\\lib\\site-packages\\dask\\dataframe\\io\\hdf.py\u001b[0m in \u001b[0;36m_read_single_hdf\u001b[1;34m(path, key, start, stop, columns, chunksize, sorted_index, lock, mode)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     return concat([one_path_one_key(path, k, start, s, columns, chunksize, d, lock)\n\u001b[1;32m--> 332\u001b[1;33m                    for k, s, d in zip(keys, stops, divisions)])\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\psc_env\\lib\\site-packages\\dask\\dataframe\\multi.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(dfs, axis, join, interleave_partitions)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dfs must be a list of DataFrames/Series objects\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No objects to concatenate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "#dd.read_hdf('myfile.1.hdf5', '/x')  \n",
    "# dd_to_pd_frame = dd.read_hdf(pattern='yellow_tripdata_2017.1.h5', key='/x') #.compute()\n",
    "dd_to_pd_frame = dd.read_hdf('yellow_tripdata_2017.1.h5','/df') #.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
